{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENG 550 Final Project\n",
    "### Use the Amazon Appliances reviews dataset to develop a classifier or sentiment analyzer that can predict whether a given review is favorable or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "Our project uses the Amazon Appliances [reviews dataset](https://amazon-reviews-2023.github.io/) to develop a sentiment analyzer classification model. By combining star ratings and textual content, the model is trained to predict whether a review leans positively or negatively towards a product. This approach offers a way to quickly grasp the general sentiment of a product and assist shoppers in filtering through large volumes of product feedback more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "### Selected Problem\n",
    "\n",
    "The problem aims to distinguish between favourable and unfavourable appliance reviews based on their text and accompanying reviews.\n",
    "\n",
    "### Why is it Important?\n",
    "\n",
    "Spending time reading review after review on a product becomes a burden. It is easy to misinterpret the mood behind a set of comments online which can easily lead to poor purchase decisions. A quick, automated sentiment indicator can ease the burden and establish a neutral decision making process.\n",
    "\n",
    "### What have Others Done in this Space?\n",
    "\n",
    "Researchers have performed [sentiment analysis](https://medium.com/@nafisaidris413/a-beginners-guide-for-product-review-sentiment-analysis-0de1f451167d) using Machine Learning and Natural Language Processing to automatically classify reviews as positive, negative, or neutral. Not only has sentiment analysis been applied to product reviews, it has also been applied to [social media](https://buffer.com/social-media-terms/sentiment-analysis) to determine how people perceive and talk about products and brands. This proves that data-driven classifiers are able to provide sentiment analysis scores for assist people in their daily lives, whether its to determine how their personal brand is viewed or how a to make an informed purchase through product review.\n",
    "\n",
    "### Existing gaps?\n",
    "\n",
    "Current solutions rely on product ratings to provide consumers with a sense of trust and quality to help them make purchasing decisions. This can be seen simply by going to any Amazon product and checking the reviews. Some reviews are informative with many positives about the product, though the product receives less than a rating of 5-stars, or the review is not informative whatsoever with a rating of 5-stars. Other times the reviews are clearly biased or the customer who leaves the review is disgruntled, leading to a 1- or 2-star rating. Using a combination of product star rating and textual review content, we are attempting to reveal patterns in product reviews that a rating alone might miss.\n",
    "\n",
    "### Data Analysis Questions\n",
    "\n",
    "1. Does text-based features add value beyond just a numerical rating?\n",
    "2. Are there certain words which portray a stronger positve or negative sentiment?\n",
    "3. How will adding text preprocessing impact accuracy?\n",
    "4. Which models work best with this data?\n",
    "\n",
    "### What is Proposed\n",
    "\n",
    "We are proposing a text classification pipeline that merges a product's star rating and textual features.\n",
    "\n",
    "### What are your Main Findings?\n",
    "\n",
    "To determine customer opinion on various products within the Appliance category in Amazon's online store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "### Exploration of Data Features and Refinement of Feature Space\n",
    "\n",
    "In this section, we focused on understanding the raw data collected from the collected [datasets](https://amazon-reviews-2023.github.io/) and transform them into a format suitable for model training. We begin by loading the Amazon Appliance reviews dataset and its corresponding metadata. We will explore the structure of the data, examine the distribution of fields we are interested in (like ratings), and assess the overall quality of the text reviews associated with the products. After we gain a thorough understanding, we apply a series of preprocessing techniques to clean and refine the text data. The goal here is to ultimately develop a set of features that can be fed into a machine learning model for sentiment classification.\n",
    "\n",
    "#### Key Steps\n",
    "\n",
    "1. **Loading the Data:**\n",
    "We will loaf the `Appliances.jsonl` (reviews) and `meta_Appliances.jsonl` (metadata) using Apache Spark to avoid memory overload\n",
    "\n",
    "2. **Initial Inspection and Basic Statistics:**\n",
    "We will look at a few sample rows, check data types, count missing values, and examine distributions.\n",
    "\n",
    "3. **Textual Data Exploration:**\n",
    "We consider the nature of each review such as its length, the character composition, and common words. This should help guide our text cleaning decision.\n",
    "\n",
    "4. **Data Cleaning:**\n",
    "We clean the text by methods such as lowercasing the characters, removing punctuation, stripping leading and/or trailing whitespaces.\n",
    "\n",
    "5. **Feature Transformation:**\n",
    "We will use Spark Machine Learning's feature extraction tools to convert raw text into numeric features that are typically suitable for machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Data\n",
    "\n",
    "The datasets are provided in `*.jsonl` format, which means each line is a separate JSON object representing a single review or product's metadata. We will use `SparkSession` to read the files which will handle the data in a distributed manner, effectively avoiding a potential kernel crash. Spark's lazy evaluation, transformations, and actions will manage memory usage of the large `.jsonl` files.\n",
    "\n",
    "The two main data sources:\n",
    "1. **Review File (`Appliances.jsonl`):**\n",
    "Contains user-level reviews with fields such as `rating`, `title`, `text`, and `helpful_vote`.\n",
    "\n",
    "2. **Metada File (`meta_Appliaces.jsonl`):**\n",
    "Contains product-level information like `main_category`, `average_rating`, and `price`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, isnan, when, count, expr, sum, size, lower, regexp_replace, min, avg, max, length, stddev, substring\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, IntegerType, ArrayType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a Spark Session\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .master(\"local[*]\")     \n",
    "        .appName(\"Amazon Review Analysis\")\n",
    "        .config(\"spark.driver.memory\", \"4g\")\n",
    "        .config(\"spark.executor.memory\", \"4g\")\n",
    "        .config(\"spark.sql.autoBroadcastJoinThreshold\", -1)\n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "def create_schema(fields):\n",
    "    return StructType([StructField(name, dtype, True) for name, dtype in fields])\n",
    "\n",
    "# Only using columns needed for analysis for Reviews\n",
    "reviews_schema = create_schema([\n",
    "    (\"rating\", FloatType()),\n",
    "    (\"title\", StringType()),\n",
    "    (\"text\", StringType()),\n",
    "    (\"helpful_vote\", IntegerType()),\n",
    "    (\"asin\", StringType()),\n",
    "    (\"parent_asin\", StringType())\n",
    "])\n",
    "\n",
    "# Only using columns needed for analysis for Metadata\n",
    "meta_schema = create_schema([\n",
    "    (\"main_category\", StringType()),\n",
    "    (\"title\", StringType()),\n",
    "    (\"average_rating\", FloatType()),\n",
    "    (\"rating_number\", IntegerType()),\n",
    "    (\"price\", FloatType()),\n",
    "    (\"categories\", ArrayType(StringType())),\n",
    "    (\"parent_asin\", StringType())\n",
    "])\n",
    "\n",
    "# Point to the location where the .jsonl files are\n",
    "data_files = {\n",
    "    \"reviews\": \"./datasets/Appliances.jsonl\",\n",
    "    \"meta\": \"./datasets/meta_Appliances.jsonl\"\n",
    "    \n",
    "}\n",
    "\n",
    "# Use the schema when reading the JSON file for Reviews\n",
    "df_reviews = spark.read.schema(reviews_schema).json(data_files[\"reviews\"])\n",
    "\n",
    "# Use the schema when reading the JSON file for Meta\n",
    "df_meta = spark.read.schema(meta_schema).json(data_files[\"meta\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Inspection & Basic Statistics\n",
    "\n",
    "First it is important to understand the size of the dataset we are dealing with and the distribution of ratings. Using Spark actions like `show()` and `count()` we determine some initial statistics about both datasets which will be helpful to visualize them. We also would like to know how many values in each column of the datasets are `null`, `None`, and `NaN`, in case we need to do some backfilling or should ignore those sets completely. We can also display a few rows of each dataset which makes sure that the datasets were loaded successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Structure Inspection\n",
    "\n",
    "For the structure of each dataset we will check the datasets dimensions, schema, and preview the data to understand each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Structure Inpsection Function\n",
    "\n",
    "def structure_inspection(df, name):\n",
    "    # Print Dimensions\n",
    "    print(f\"{name} Dimensions: {df.count()} rows, {len(df.columns)} columns\")\n",
    "    \n",
    "    # Print Schema\n",
    "    print(f\"\\n{name} Schema:\")\n",
    "    df.printSchema()\n",
    "    \n",
    "    # Preview Data\n",
    "    print(f\"\\n{name} Preview:\")\n",
    "    df.show(10, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appliance Reviews Dimensions: 2128605 rows, 6 columns\n",
      "\n",
      "Appliance Reviews Schema:\n",
      "root\n",
      " |-- rating: float (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- helpful_vote: integer (nullable = true)\n",
      " |-- asin: string (nullable = true)\n",
      " |-- parent_asin: string (nullable = true)\n",
      "\n",
      "\n",
      "Appliance Reviews Preview:\n",
      "+------+--------------------+--------------------+------------+----------+-----------+\n",
      "|rating|               title|                text|helpful_vote|      asin|parent_asin|\n",
      "+------+--------------------+--------------------+------------+----------+-----------+\n",
      "|   5.0|          Work great|work great. use a...|           0|B01N0TQ0OH| B01N0TQ0OH|\n",
      "|   5.0|   excellent product|Little on the thi...|           0|B07DD2DMXB| B07DD37QPZ|\n",
      "|   5.0|     Happy customer!|Quick delivery, f...|           0|B082W3Z9YK| B082W3Z9YK|\n",
      "|   5.0|       Amazing value|I wasn't sure whe...|           0|B078W2BJY8| B078W2BJY8|\n",
      "|   5.0|         Dryer parts|Easy to install g...|           0|B08C9LPCQV| B08C9LPCQV|\n",
      "|   5.0|DO NOT purchase t...|After buying this...|           0|B08D6RFV6D| B099ZKQJHK|\n",
      "|   2.0|They don't fit pr...|Not the best quality|           0|B001TH7GZA| B001TH7H0O|\n",
      "|   5.0|          Five Stars|Part came quickly...|           0|B00AF7WZTM| B00AF7WZTM|\n",
      "|   5.0|          Five Stars|Always arrive in ...|           0|B001H05AXY| B001H05AXY|\n",
      "|   2.0|Company is phenom...|The company respo...|           0|B085C6C7WH| B085C6C7WH|\n",
      "+------+--------------------+--------------------+------------+----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect Reviews\n",
    "structure_inspection(df_reviews, \"Appliance Reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appliance Metadata Dimensions: 94327 rows, 7 columns\n",
      "\n",
      "Appliance Metadata Schema:\n",
      "root\n",
      " |-- main_category: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- average_rating: float (nullable = true)\n",
      " |-- rating_number: integer (nullable = true)\n",
      " |-- price: float (nullable = true)\n",
      " |-- categories: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- parent_asin: string (nullable = true)\n",
      "\n",
      "\n",
      "Appliance Metadata Preview:\n",
      "+--------------------+--------------------+--------------+-------------+-----+--------------------+-----------+\n",
      "|       main_category|               title|average_rating|rating_number|price|          categories|parent_asin|\n",
      "+--------------------+--------------------+--------------+-------------+-----+--------------------+-----------+\n",
      "|Industrial & Scie...|ROVSUN Ice Maker ...|           3.7|           61| NULL|[Appliances, Refr...| B08Z743RRD|\n",
      "|Tools & Home Impr...|HANSGO Egg Holder...|           4.2|           75| NULL|[Appliances, Part...| B097BQDGHJ|\n",
      "|Tools & Home Impr...|Clothes Dryer Dru...|           3.5|           18| NULL|[Appliances, Part...| B00IN9AGAE|\n",
      "|Tools & Home Impr...|154567702 Dishwas...|           4.5|           26| NULL|[Appliances, Part...| B0C7K98JZS|\n",
      "|Tools & Home Impr...|Whirlpool W109185...|           3.8|           12|25.07|[Appliances, Part...| B07QZHQTVJ|\n",
      "|Tools & Home Impr...|1841N030 - Brown ...|           4.5|            7| NULL|[Appliances, Part...| B00GS4892I|\n",
      "|          Appliances|WD12X10327 Rack R...|           4.6|          323| 8.99|[Appliances, Part...| B07W42P978|\n",
      "|Tools & Home Impr...|SAMSUNG Cap-Handl...|           4.0|           12|53.68|[Appliances, Part...| B078ZF9JS1|\n",
      "|         Amazon Home|G.a HOMEFAVOR Col...|           4.5|          326| NULL|[Small Appliance ...| B083Q6Y54F|\n",
      "|Tools & Home Impr...|3-pack OnePurify ...|           4.3|          236| NULL|[Appliances, Part...| B00KAS9ZMG|\n",
      "+--------------------+--------------------+--------------+-------------+-----+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect Metadata\n",
    "structure_inspection(df_meta, \"Appliance Metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values Inspection\n",
    "\n",
    "Missing values is one of the most common headaches in datasets. We need to check for them in both datasets to ensure that we can confidently use the data, else we have to consider backfilling the missing data or not using it at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nulls_counter(df, col_dtypes):\n",
    "    null_dfs = []\n",
    "    for col_dtype, cols in col_dtypes.items():\n",
    "        if col_dtype in [\"float\", \"integer\"]:\n",
    "            null_dfs.append(df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in cols]))\n",
    "        elif col_dtype == \"string\":\n",
    "            null_dfs.append(df.select([sum((col(c).isNull() | (col(c) == \"\")).cast(\"int\")).alias(c) for c in cols]))\n",
    "        elif col_dtype == \"array\":\n",
    "            null_dfs.append(df.select([sum((col(c).isNull() | expr(f\"exists({c}, x -> x == '')\")).cast(\"int\")).alias(c) for c in cols]))\n",
    "\n",
    "    # Combine all null DataFrames using reduce\n",
    "    return reduce(lambda df1, df2: df1.crossJoin(df2), null_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_missing_values(df, name):\n",
    "    col_dtypes = {\n",
    "        \"float\": [c for c in df.columns if df.schema[c].dataType.simpleString() == \"float\"],\n",
    "        \"string\": [c for c in df.columns if df.schema[c].dataType.simpleString() == \"string\"],\n",
    "        \"integer\": [c for c in df.columns if df.schema[c].dataType.simpleString() == \"int\"],\n",
    "        \"array\": [c for c in df.columns if df.schema[c].dataType.simpleString().startswith(\"array\")]\n",
    "    }\n",
    "    \n",
    "    null_counter = get_nulls_counter(df, col_dtypes)\n",
    "    \n",
    "    print(f\"{name} Counted Missing Values per Column:\")\n",
    "    null_counter.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appliance Reviews Counted Missing Values per Column:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:>                                                       (0 + 12) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+----+----+-----------+------------+\n",
      "|rating|title|text|asin|parent_asin|helpful_vote|\n",
      "+------+-----+----+----+-----------+------------+\n",
      "|     0|    0|  95|   0|          0|           0|\n",
      "+------+-----+----+----+-----------+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print_missing_values(df_reviews, \"Appliance Reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appliance Metadata Counted Missing Values per Column:\n",
      "+--------------+-----+-------------+-----+-----------+-------------+----------+\n",
      "|average_rating|price|main_category|title|parent_asin|rating_number|categories|\n",
      "+--------------+-----+-------------+-----+-----------+-------------+----------+\n",
      "|             0|47601|         4676|    9|          0|            0|         0|\n",
      "+--------------+-----+-------------+-----+-----------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_missing_values(df_meta, \"Appliance Metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicates\n",
    "\n",
    "Catching if there is duplicate data is important so that we do not have skewed data. All the data should be unique. Duplicate data will be handled during data cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_data(df, name):\n",
    "    total_count = df.count()\n",
    "    distinct_count = df.distinct().count()\n",
    "    duplicate_count = total_count - distinct_count\n",
    "    print(f\"{name} Duplicate Data: {duplicate_count}\\n(Total: {total_count}, Distinct: {distinct_count})\")       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:>                                                       (0 + 12) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appliance Reviews Duplicate Data: 29492\n",
      "(Total: 2128605, Distinct: 2099113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "duplicate_data(df_reviews, \"Appliance Reviews\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:>                                                       (0 + 12) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appliance Metadata Duplicate Data: 0\n",
      "(Total: 94327, Distinct: 94327)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "duplicate_data(df_meta, \"Appliance Metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Data\n",
    "\n",
    "We examine the statistical summaries for both the Reviews and Metadata. This helps us spot outliers and check if there are unexpected ranges that we have to look out for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appliance Reviews Statistical Summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:====>                                                   (1 + 11) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+--------------------+------------------+--------------------+--------------------+\n",
      "|summary|            rating|               title|                text|      helpful_vote|                asin|         parent_asin|\n",
      "+-------+------------------+--------------------+--------------------+------------------+--------------------+--------------------+\n",
      "|  count|           2128605|             2128605|             2128605|           2128605|             2128605|             2128605|\n",
      "|   mean| 4.221502345432807|                 NaN|1.0294495574587156E9|0.9288867591685634|1.5550635848728814E9|1.5550635848728814E9|\n",
      "| stddev|1.3808261737697285|                 NaN|1.064196457532015...|12.526794316769463|1.4548141211071749E9|1.4548141211071749E9|\n",
      "|    min|               1.0|                   !|                    |                 0|          0967805929|          0967805929|\n",
      "|    max|               5.0|🧊🥶 AMAZING 🤩  ...|🧐doesn’t filter ...|              5704|          B0CFQVYFWC|          B0CKR66M1V|\n",
      "+-------+------------------+--------------------+--------------------+------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"Appliance Reviews Statistical Summary\")\n",
    "df_reviews.describe().show(truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appliance Metadata Statistical Summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 60:>                                                       (0 + 12) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+--------------------+------------------+------------------+------------------+--------------------+\n",
      "|summary| main_category|               title|    average_rating|     rating_number|             price|         parent_asin|\n",
      "+-------+--------------+--------------------+------------------+------------------+------------------+--------------------+\n",
      "|  count|         89651|               94327|             94327|             94327|             46726|               94327|\n",
      "|   mean|          NULL|  1.1113368793875E10| 4.118858857941276|136.36790102515715|  86.4799539034291|4.0776468745555553E9|\n",
      "| stddev|          NULL|3.142601103602334E10|0.8640397544170938| 977.5160999553573|325.31839674168475| 3.745278366512328E9|\n",
      "|    min|AMAZON FASHION|                    |               1.0|                 1|              0.01|          0967805929|\n",
      "|    max|   Video Games|𝟮𝟬𝟮𝟯𝙪𝙥𝙜𝙧?...|               5.0|             90203|          21095.62|          B0CKR66M1V|\n",
      "+-------+--------------+--------------------+------------------+------------------+------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"Appliance Metadata Statistical Summary\")\n",
    "df_meta.describe().show(truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textual Data Exploration\n",
    "\n",
    "The main predictive feature of the model will likely be the `text` column in the Appliance Review dataset. It is important that we are able to understand its quality. We find answers to questions such as are the reviews too short or lone? Do they contain descriptive terms or just a few words? We also need to consider if there is text in different languages other than english.\n",
    "\n",
    "What we will do is start by analyzing the length of the reviews in terms of word count. This will help guide us in the direction we want. If the text is too short, maybe we need to rely more on ratings or metadata. If text is rich, a text-based sentiment analysis may just work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appliance Reviews with Word Count and Character Length Included\n",
      "+------+--------------------+--------------------+------------+----------+-----------+--------------------+----------------+----------+\n",
      "|rating|               title|                text|helpful_vote|      asin|parent_asin|           words_raw|character_length|word_count|\n",
      "+------+--------------------+--------------------+------------+----------+-----------+--------------------+----------------+----------+\n",
      "|   5.0|          Work great|work great. use a...|           0|B01N0TQ0OH| B01N0TQ0OH|[work, great., us...|              37|         8|\n",
      "|   5.0|   excellent product|Little on the thi...|           0|B07DD2DMXB| B07DD37QPZ|[little, on, the,...|              23|         5|\n",
      "|   5.0|     Happy customer!|Quick delivery, f...|           0|B082W3Z9YK| B082W3Z9YK|[quick, delivery,...|              32|         5|\n",
      "|   5.0|       Amazing value|I wasn't sure whe...|           0|B078W2BJY8| B078W2BJY8|[i, wasn't, sure,...|             299|        57|\n",
      "|   5.0|         Dryer parts|Easy to install g...|           0|B08C9LPCQV| B08C9LPCQV|[easy, to, instal...|              51|         9|\n",
      "|   5.0|DO NOT purchase t...|After buying this...|           0|B08D6RFV6D| B099ZKQJHK|[after, buying, t...|             166|        33|\n",
      "|   2.0|They don't fit pr...|Not the best quality|           0|B001TH7GZA| B001TH7H0O|[not, the, best, ...|              20|         4|\n",
      "|   5.0|          Five Stars|Part came quickly...|           0|B00AF7WZTM| B00AF7WZTM|[part, came, quic...|              47|        10|\n",
      "|   5.0|          Five Stars|Always arrive in ...|           0|B001H05AXY| B001H05AXY|[always, arrive, ...|              78|        14|\n",
      "|   2.0|Company is phenom...|The company respo...|           0|B085C6C7WH| B085C6C7WH|[the, company, re...|             125|        22|\n",
      "+------+--------------------+--------------------+------------+----------+-----------+--------------------+----------------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "Summary Statistics for Appliance Reviews:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 64:==============================================>         (10 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+------------------+---------------+--------------+-----------------+-----------------+--------------+\n",
      "|min_char_length|   avg_char_length|stddev_char_length|max_char_length|min_word_count|   avg_word_count|stddev_word_count|max_word_count|\n",
      "+---------------+------------------+------------------+---------------+--------------+-----------------+-----------------+--------------+\n",
      "|             10|175.58352814723935|283.32226996999367|          30004|             1|33.16792796286858|53.12268670108261|          3740|\n",
      "+---------------+------------------+------------------+---------------+--------------+-----------------+-----------------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Fill null text fields and cast text to string\n",
    "df_reviews = df_reviews.fillna({\"text\": \"\"}).withColumn(\"text\", col(\"text\").cast(\"string\"))\n",
    "\n",
    "# Tokenize text and calculate character length and word count\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words_raw\")\n",
    "df_tokenizer_reviews = (\n",
    "    tokenizer\n",
    "    .transform(df_reviews)\n",
    "    .withColumn(\"character_length\", length(col(\"text\")))\n",
    "    .withColumn(\"word_count\", size(col(\"words_raw\")))\n",
    "    .filter(col(\"character_length\") > 9)\n",
    ")\n",
    "\n",
    "# Show summary statistics for word count and character length\n",
    "print(\"Appliance Reviews with Word Count and Character Length Included\")\n",
    "df_tokenizer_reviews.show(10, truncate=True)\n",
    "\n",
    "print(\"\\nSummary Statistics for Appliance Reviews:\")\n",
    "df_tokenizer_reviews.select(\n",
    "    min(\"character_length\").alias(\"min_char_length\"),\n",
    "    avg(\"character_length\").alias(\"avg_char_length\"),\n",
    "    stddev(\"character_length\").alias(\"stddev_char_length\"),\n",
    "    max(\"character_length\").alias(\"max_char_length\"),\n",
    "    min(\"word_count\").alias(\"min_word_count\"),\n",
    "    avg(\"word_count\").alias(\"avg_word_count\"),\n",
    "    stddev(\"word_count\").alias(\"stddev_word_count\"),\n",
    "    max(\"word_count\").alias(\"max_word_count\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "Data Cleaning is an important part of the process so that duplicated data or data with missing information is not included in the Machine Learning model. This keeps the model from skewing too much, in turn allowing the model to be as free from Bias and Variance as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Code Block` below removes duplicate data from the `Appliances.jsonl` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Row Count: 2128605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:>                                                       (0 + 12) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Row Count: 2099018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Removing Duplicates\n",
    "df_reviews_clean = df_reviews.dropDuplicates()\n",
    "\n",
    "df_reviews_clean = df_reviews_clean.filter(\n",
    "    (col(\"text\").isNotNull()) & (col(\"text\") != \"\")\n",
    ")\n",
    "\n",
    "print(\"Original Row Count:\", df_reviews.count())\n",
    "print(\"Cleaned Row Count:\", df_reviews_clean.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following `Code Block` just shows a sample of the Cleaned Dataset with no duplicates. This likely won't be much different from the previous Dataset sample, though we know that there is no duplicates in this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Reviews Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 76:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+------------+----------+-----------+\n",
      "|rating|               title|                text|helpful_vote|      asin|parent_asin|\n",
      "+------+--------------------+--------------------+------------+----------+-----------+\n",
      "|   5.0|Easy setup and wo...|I love how easy t...|           0|B00UXG4WR8| B00UXG4WR8|\n",
      "|   5.0|              buy it|fit, look, & work...|           0|B001TH7GZU| B001TH7GZU|\n",
      "|   5.0|             Filters|Yep, got what I n...|           0|B07CV7VNL8| B07CV7VNL8|\n",
      "|   5.0|Flawless Version ...|We don't have any...|           2|B09649DDTN| B0C9TTZW3K|\n",
      "|   5.0|A great dish. A g...|The Apusafe MWF w...|           0|B0892F62TR| B0892F62TR|\n",
      "|   2.0|I wanted to love ...|I bought this to ...|           2|B08PYPQQ3Z| B08PYPQQ3Z|\n",
      "|   5.0|   Holds jumbo eggs!|This particular e...|           4|B01EVRIK2C| B07MBQW54M|\n",
      "|   5.0|    I have ice again|This solved my NO...|           0|B01GXOPMW2| B01GXOPMW2|\n",
      "|   5.0|Useful to rinse q...|Quinoa is too sma...|           0|B0001IRRLG| B0BHNSLKNZ|\n",
      "|   2.0|   a little too late|I personally don'...|           0|B00W8MO0UO| B0B6Y2D91L|\n",
      "+------+--------------------+--------------------+------------+----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Cleaned Reviews Dataset:\")\n",
    "df_reviews_clean.show(10, truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "This step is similar to the ***Textual Data Exploration*** step, with the exception that it is performed on the cleaned data.\n",
    "\n",
    "This step is used to transform the `text` column of the reviews dataset into numerical features that a machine learning model can understand. We used ***TF-IDF (Term Frequency-Inverse Document Frequency)*** to represent the importance of words in each review while reducing the influence of commonly used words. This step involves tokenizing the text, removing stopwords, and applying TF-IDF transformation to create a feature vector for each review.\n",
    "\n",
    "First we `Tokenize` the text as shown in the following `Code Block`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 79:==========================================>              (9 + 3) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+------------+----------+-----------+--------------------+\n",
      "|rating|               title|                text|helpful_vote|      asin|parent_asin|           words_raw|\n",
      "+------+--------------------+--------------------+------------+----------+-----------+--------------------+\n",
      "|   5.0|Easy setup and wo...|I love how easy t...|           0|B00UXG4WR8| B00UXG4WR8|[i, love, how, ea...|\n",
      "|   5.0|              buy it|fit, look, & work...|           0|B001TH7GZU| B001TH7GZU|[fit,, look,, &, ...|\n",
      "|   5.0|             Filters|Yep, got what I n...|           0|B07CV7VNL8| B07CV7VNL8|[yep,, got, what,...|\n",
      "|   5.0|Flawless Version ...|We don't have any...|           2|B09649DDTN| B0C9TTZW3K|[we, don't, have,...|\n",
      "|   5.0|A great dish. A g...|The Apusafe MWF w...|           0|B0892F62TR| B0892F62TR|[the, apusafe, mw...|\n",
      "|   2.0|I wanted to love ...|I bought this to ...|           2|B08PYPQQ3Z| B08PYPQQ3Z|[i, bought, this,...|\n",
      "|   5.0|   Holds jumbo eggs!|This particular e...|           4|B01EVRIK2C| B07MBQW54M|[this, particular...|\n",
      "|   5.0|    I have ice again|This solved my NO...|           0|B01GXOPMW2| B01GXOPMW2|[this, solved, my...|\n",
      "|   5.0|Useful to rinse q...|Quinoa is too sma...|           0|B0001IRRLG| B0BHNSLKNZ|[quinoa, is, too,...|\n",
      "|   2.0|   a little too late|I personally don'...|           0|B00W8MO0UO| B0B6Y2D91L|[i, personally, d...|\n",
      "+------+--------------------+--------------------+------------+----------+-----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Remove HTML tags from the 'text' column using regexp_replace\n",
    "df_reviews_clean = df_reviews_clean.withColumn(\n",
    "    \"text\", regexp_replace(col(\"text\"), \"<[^>]+>\", \"\")  # Remove anything between < and >\n",
    ")\n",
    "\n",
    "# Tokenization - Split the 'text' column into individual words\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words_raw\")\n",
    "df_reviews_tokenized = tokenizer.transform(df_reviews_clean)\n",
    "\n",
    "df_reviews_tokenized.show(10, truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the text has been tokenized (which we see in the `words_raw` column), we want to remove common words like _\"the\"_, _\"and\"_, _\"I\"_, etc. To accomplish this, we use Spark's `StopWordsRemover` function. This is applied in the following `Code Block`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 82:====>                                                   (1 + 11) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+------------+----------+-----------+--------------------+--------------------+\n",
      "|rating|               title|                text|helpful_vote|      asin|parent_asin|           words_raw|       words_cleaned|\n",
      "+------+--------------------+--------------------+------------+----------+-----------+--------------------+--------------------+\n",
      "|   5.0|Easy setup and wo...|I love how easy t...|           0|B00UXG4WR8| B00UXG4WR8|[i, love, how, ea...|[love, easy, filt...|\n",
      "|   5.0|              buy it|fit, look, & work...|           0|B001TH7GZU| B001TH7GZU|[fit,, look,, &, ...|[fit,, look,, &, ...|\n",
      "|   5.0|             Filters|Yep, got what I n...|           0|B07CV7VNL8| B07CV7VNL8|[yep,, got, what,...|[yep,, got, needed.]|\n",
      "|   5.0|Flawless Version ...|We don't have any...|           2|B09649DDTN| B0C9TTZW3K|[we, don't, have,...|[ice, maker, free...|\n",
      "|   5.0|A great dish. A g...|The Apusafe MWF w...|           0|B0892F62TR| B0892F62TR|[the, apusafe, mw...|[apusafe, mwf, wa...|\n",
      "|   2.0|I wanted to love ...|I bought this to ...|           2|B08PYPQQ3Z| B08PYPQQ3Z|[i, bought, this,...|[bought, take, ex...|\n",
      "|   5.0|   Holds jumbo eggs!|This particular e...|           4|B01EVRIK2C| B07MBQW54M|[this, particular...|[particular, egg,...|\n",
      "|   5.0|    I have ice again|This solved my NO...|           0|B01GXOPMW2| B01GXOPMW2|[this, solved, my...|[solved, ice, pro...|\n",
      "|   5.0|Useful to rinse q...|Quinoa is too sma...|           0|B0001IRRLG| B0BHNSLKNZ|[quinoa, is, too,...|[quinoa, small, r...|\n",
      "|   2.0|   a little too late|I personally don'...|           0|B00W8MO0UO| B0B6Y2D91L|[i, personally, d...|[personally, drin...|\n",
      "+------+--------------------+--------------------+------------+----------+-----------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Stopwords Removal\n",
    "stopwords_remover = StopWordsRemover(inputCol=\"words_raw\", outputCol=\"words_cleaned\")\n",
    "df_reviews_cleaned_words = stopwords_remover.transform(df_reviews_tokenized)\n",
    "\n",
    "df_reviews_cleaned_words.show(10, truncate=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a new column using the `StopWordsRemover` function, named `words_cleaned`, which has removed all the common words.\n",
    "\n",
    "Next, we needed to make these words meaningful to the Machine Learning model. To do this we converted the words into a term frequency vector. Because of the Appliances.jsonl dataset being so large, we capped the vocab size of it at 5000 to save computer resources. We used Spark's `CountVectorizer` function to turn the words into a frequency vector in the following `Code Block`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 92:====>                                                   (1 + 11) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+------------+----------+-----------+--------------------+--------------------+--------------------+\n",
      "|rating|               title|                text|helpful_vote|      asin|parent_asin|           words_raw|       words_cleaned|        raw_features|\n",
      "+------+--------------------+--------------------+------------+----------+-----------+--------------------+--------------------+--------------------+\n",
      "|   5.0|Easy setup and wo...|I love how easy t...|           0|B00UXG4WR8| B00UXG4WR8|[i, love, how, ea...|[love, easy, filt...|(5000,[2,9,26,31,...|\n",
      "|   5.0|              buy it|fit, look, & work...|           0|B001TH7GZU| B001TH7GZU|[fit,, look,, &, ...|[fit,, look,, &, ...|(5000,[1,16,155,5...|\n",
      "|   5.0|             Filters|Yep, got what I n...|           0|B07CV7VNL8| B07CV7VNL8|[yep,, got, what,...|[yep,, got, needed.]|(5000,[41,310],[1...|\n",
      "|   5.0|Flawless Version ...|We don't have any...|           2|B09649DDTN| B0C9TTZW3K|[we, don't, have,...|[ice, maker, free...|(5000,[0,3,5,7,10...|\n",
      "|   5.0|A great dish. A g...|The Apusafe MWF w...|           0|B0892F62TR| B0892F62TR|[the, apusafe, mw...|[apusafe, mwf, wa...|(5000,[5,6,14,21,...|\n",
      "|   2.0|I wanted to love ...|I bought this to ...|           2|B08PYPQQ3Z| B08PYPQQ3Z|[i, bought, this,...|[bought, take, ex...|(5000,[3,7,11,13,...|\n",
      "|   5.0|   Holds jumbo eggs!|This particular e...|           4|B01EVRIK2C| B07MBQW54M|[this, particular...|[particular, egg,...|(5000,[0,39,41,49...|\n",
      "|   5.0|    I have ice again|This solved my NO...|           0|B01GXOPMW2| B01GXOPMW2|[this, solved, my...|[solved, ice, pro...|(5000,[2,3,4,7,10...|\n",
      "|   5.0|Useful to rinse q...|Quinoa is too sma...|           0|B0001IRRLG| B0BHNSLKNZ|[quinoa, is, too,...|[quinoa, small, r...|(5000,[11,61,102,...|\n",
      "|   2.0|   a little too late|I personally don'...|           0|B00W8MO0UO| B0B6Y2D91L|[i, personally, d...|[personally, drin...|(5000,[0,6,12,16,...|\n",
      "+------+--------------------+--------------------+------------+----------+-----------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# CountVectorizer - Convert words into a term frequency vector\n",
    "count_vectorizer = CountVectorizer(inputCol=\"words_cleaned\", outputCol=\"raw_features\", vocabSize=5000)\n",
    "cv_model = count_vectorizer.fit(df_reviews_cleaned_words)\n",
    "df_reviews_vectorized = cv_model.transform(df_reviews_cleaned_words)\n",
    "\n",
    "df_reviews_vectorized.show(10, truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a Term Frequency shown in the `raw_features` column, we can use Spark's `IDF` function to apply an Inverse Document Frequency. This will weight the importance of each word in the document, so that we can determine the Sentiment Analysis of each review, if they are helpful or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 99:>                                                       (0 + 12) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+\n",
      "|rating|               title|                text|helpful_vote|      asin|parent_asin|           words_raw|       words_cleaned|        raw_features|      tfidf_features|\n",
      "+------+--------------------+--------------------+------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+\n",
      "|   5.0|Easy setup and wo...|I love how easy t...|           0|B00UXG4WR8| B00UXG4WR8|[i, love, how, ea...|[love, easy, filt...|(5000,[2,9,26,31,...|(5000,[2,9,26,31,...|\n",
      "|   5.0|              buy it|fit, look, & work...|           0|B001TH7GZU| B001TH7GZU|[fit,, look,, &, ...|[fit,, look,, &, ...|(5000,[1,16,155,5...|(5000,[1,16,155,5...|\n",
      "|   5.0|             Filters|Yep, got what I n...|           0|B07CV7VNL8| B07CV7VNL8|[yep,, got, what,...|[yep,, got, needed.]|(5000,[41,310],[1...|(5000,[41,310],[3...|\n",
      "|   5.0|Flawless Version ...|We don't have any...|           2|B09649DDTN| B0C9TTZW3K|[we, don't, have,...|[ice, maker, free...|(5000,[0,3,5,7,10...|(5000,[0,3,5,7,10...|\n",
      "|   5.0|A great dish. A g...|The Apusafe MWF w...|           0|B0892F62TR| B0892F62TR|[the, apusafe, mw...|[apusafe, mwf, wa...|(5000,[5,6,14,21,...|(5000,[5,6,14,21,...|\n",
      "|   2.0|I wanted to love ...|I bought this to ...|           2|B08PYPQQ3Z| B08PYPQQ3Z|[i, bought, this,...|[bought, take, ex...|(5000,[3,7,11,13,...|(5000,[3,7,11,13,...|\n",
      "|   5.0|   Holds jumbo eggs!|This particular e...|           4|B01EVRIK2C| B07MBQW54M|[this, particular...|[particular, egg,...|(5000,[0,39,41,49...|(5000,[0,39,41,49...|\n",
      "|   5.0|    I have ice again|This solved my NO...|           0|B01GXOPMW2| B01GXOPMW2|[this, solved, my...|[solved, ice, pro...|(5000,[2,3,4,7,10...|(5000,[2,3,4,7,10...|\n",
      "|   5.0|Useful to rinse q...|Quinoa is too sma...|           0|B0001IRRLG| B0BHNSLKNZ|[quinoa, is, too,...|[quinoa, small, r...|(5000,[11,61,102,...|(5000,[11,61,102,...|\n",
      "|   2.0|   a little too late|I personally don'...|           0|B00W8MO0UO| B0B6Y2D91L|[i, personally, d...|[personally, drin...|(5000,[0,6,12,16,...|(5000,[0,6,12,16,...|\n",
      "+------+--------------------+--------------------+------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# TF-IDF - Apply Inverse Document Frequency to weigh word importance\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"tfidf_features\")\n",
    "idf_model = idf.fit(df_reviews_vectorized)\n",
    "df_reviews_final = idf_model.transform(df_reviews_vectorized)\n",
    "\n",
    "df_reviews_final.show(10, truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an output of the raw text along with the `TF-IDF` features that will be used to determine the Sentiment Analysis of the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews Dataset with TF-IDF Features:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 102:==============>                                         (3 + 9) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|text                |tfidf_features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "+--------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|I love how easy this|(5000,[2,9,26,31,55,79,245,300,1837],[2.0005821742513694,2.7252524246114924,3.0353432451190416,3.071724474218577,3.4926887892306064,3.698097044400429,4.463616816957099,4.676864084478404,6.6826218259614105])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "|fit, look, & work gr|(5000,[1,16,155,515,4444],[1.9698209757809537,2.814754627733114,4.4268755880294535,5.182312985293433,7.942255050487531])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "|Yep, got what I need|(5000,[41,310],[3.3622377036212283,4.6347694841570615])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "|We don't have any ic|(5000,[0,3,5,7,10,23,36,65,75,80,88,89,104,114,157,162,173,180,229,230,248,251,282,335,338,379,398,410,433,539,547,594,657,664,755,1161,1202,1251,1349,1469,1489,1497,1785,1822,2364,2481,2499,2570,3000,3035,3461,3691,4042,4739],[13.95811514200683,2.291159060755906,2.532537801276672,2.3548507676438897,21.36602293453717,3.0254297215978982,3.459843394152302,3.5849964333916775,3.688259832767994,7.72435238764595,3.766651774506297,7.583866281975026,3.8875137589455484,3.920236176667342,4.110442327094436,4.159833979311083,4.418144334402592,4.4855663174788845,4.451818361456607,4.461303722162859,4.528712381257858,8.92979916920072,4.690416452259761,4.883409533756803,4.757299266880753,4.886497609316249,4.96226262293743,4.991907219013718,5.2062698258678335,5.261288611615606,5.302719091657181,5.387253961600406,5.481086375268032,11.111268813849799,5.915448185019447,6.319501362077658,6.226358030358424,6.270459277010056,6.312646602835197,6.526571088560807,6.52527027536925,6.434609407284739,6.685669447367886,6.797793212183496,7.026500655445755,7.098217958310332,7.147844206771164,7.45119452121002,7.352831358655353,7.489660802037816,7.620637914857242,7.646229862729356,7.815279956039237,8.089281924586938])|\n",
      "|The Apusafe MWF wate|(5000,[5,6,14,21,29,47,68,118,122,127,133,162,170,264,313,344,432,457,487,671,1281,1654,2561,2852,2854],[2.532537801276672,2.2415514841779456,5.515317879179479,3.0864096038027635,3.0097793707572915,6.957136253275781,3.757997085537714,3.8900039565389717,8.045400318684388,4.149239019772212,4.016413749864903,8.319667958622166,4.2584824479508585,4.5747743434437735,4.67338972986962,4.778376280301854,4.995912987046279,5.077758835727045,5.17740396146981,11.063772214052621,6.265183545642558,6.551947306054182,7.147844206771164,7.295755558719371,7.448736510959751])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "+--------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Output Verification\n",
    "print(\"Reviews Dataset with TF-IDF Features:\")\n",
    "df_verification = df_reviews_final.withColumn(\"text\", substring(\"text\", 1, 20))\n",
    "df_verification.select(\"text\", \"tfidf_features\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Setup\n",
    "\n",
    "For the Sentiment Analysis task, we focused on predicting whether a given review is favorable (positive sentiment) or unfavorable (negative sentiment). We began by creating a binary label based on the rating column, where ratings ≥ 4 are considered favorable, and ratings < 4 are unfavorable. For quick experimentation, we’ll use Logistic Regression, a simple and effective model for text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 105:>                                                      (0 + 12) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|rating|               title|                text|helpful_vote|      asin|parent_asin|           words_raw|       words_cleaned|        raw_features|      tfidf_features|label|\n",
      "+------+--------------------+--------------------+------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|   5.0|Easy setup and wo...|I love how easy t...|           0|B00UXG4WR8| B00UXG4WR8|[i, love, how, ea...|[love, easy, filt...|(5000,[2,9,26,31,...|(5000,[2,9,26,31,...|    1|\n",
      "|   5.0|              buy it|fit, look, & work...|           0|B001TH7GZU| B001TH7GZU|[fit,, look,, &, ...|[fit,, look,, &, ...|(5000,[1,16,155,5...|(5000,[1,16,155,5...|    1|\n",
      "|   5.0|             Filters|Yep, got what I n...|           0|B07CV7VNL8| B07CV7VNL8|[yep,, got, what,...|[yep,, got, needed.]|(5000,[41,310],[1...|(5000,[41,310],[3...|    1|\n",
      "|   5.0|Flawless Version ...|We don't have any...|           2|B09649DDTN| B0C9TTZW3K|[we, don't, have,...|[ice, maker, free...|(5000,[0,3,5,7,10...|(5000,[0,3,5,7,10...|    1|\n",
      "|   5.0|A great dish. A g...|The Apusafe MWF w...|           0|B0892F62TR| B0892F62TR|[the, apusafe, mw...|[apusafe, mwf, wa...|(5000,[5,6,14,21,...|(5000,[5,6,14,21,...|    1|\n",
      "|   2.0|I wanted to love ...|I bought this to ...|           2|B08PYPQQ3Z| B08PYPQQ3Z|[i, bought, this,...|[bought, take, ex...|(5000,[3,7,11,13,...|(5000,[3,7,11,13,...|    0|\n",
      "|   5.0|   Holds jumbo eggs!|This particular e...|           4|B01EVRIK2C| B07MBQW54M|[this, particular...|[particular, egg,...|(5000,[0,39,41,49...|(5000,[0,39,41,49...|    1|\n",
      "|   5.0|    I have ice again|This solved my NO...|           0|B01GXOPMW2| B01GXOPMW2|[this, solved, my...|[solved, ice, pro...|(5000,[2,3,4,7,10...|(5000,[2,3,4,7,10...|    1|\n",
      "|   5.0|Useful to rinse q...|Quinoa is too sma...|           0|B0001IRRLG| B0BHNSLKNZ|[quinoa, is, too,...|[quinoa, small, r...|(5000,[11,61,102,...|(5000,[11,61,102,...|    1|\n",
      "|   2.0|   a little too late|I personally don'...|           0|B00W8MO0UO| B0B6Y2D91L|[i, personally, d...|[personally, drin...|(5000,[0,6,12,16,...|(5000,[0,6,12,16,...|    0|\n",
      "+------+--------------------+--------------------+------------+----------+-----------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Define the target label\n",
    "# Reviews with rating >= 4 are favorable (label=1), otherwise unfavorable (label=0)\n",
    "df_reviews_labeled = df_reviews_final.withColumn(\n",
    "    \"label\", when(col(\"rating\") >= 4, 1).otherwise(0)\n",
    ")\n",
    "\n",
    "df_reviews_labeled.show(10, truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a typic 80-20 split for Train-Test data. We use a value of 42 for Seed ([The answer to \"Life, the universe and everything!\"](https://medium.com/geekculture/the-story-behind-random-seed-42-in-machine-learning-b838c4ac290a)). We can use Sparks `randomSplit` function to accomplish this in the following `Code Block`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (80-20 split)\n",
    "train_data, test_data = df_reviews_labeled.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we must use Spark's `LogisticRegression` model as the Machine Learning model we are deciding to use, and define it appropriately in the following `Code Block`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Logistic Regression model\n",
    "lr = LogisticRegression(featuresCol=\"tfidf_features\", labelCol=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we are not creating an overly complex pipeline for this task, if the need arose where we wanted to add more variables or tweak the Machine Model learning further, we have one set up to do so in the `Code Block` below, using Spark's `Pipeline` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline (no additional transformations needed here)\n",
    "pipeline = Pipeline(stages=[lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trained the data in the pipeline, which we will use to make predictions on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 285:==========================================>             (9 + 3) / 12]\r"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "lr_model = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentation Factors and Process\n",
    "\n",
    "As seen above, the Machine Learning model used for the experiment was the Logistic Regression model. We used this model because we needed to classify simply whether a given text review was Favourable or Not Favourable. We determined in the training of the model that reviews with a rating of 4 or greater must be Favourable, thus the rest would be deemed Not Favourable. Given the large nature of the dataset, we did not tune any Hyperparameters in the initial model. Though we will tune them when we run a Cross-Validation model. The hyperparameter tuned will be the Regularization parameter. We will tune it with Regularization parameters set to [0.01, 0.1, 1.0]. We will find the best model with this set and compare it to the baseline model that has no tuning. Based on this we will be able to determine which model produces the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have trained the data, now we make predictions using the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = lr_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions on the baseline model will now be evaluated, and a value which defines the Area Under the ROC will be determined. The closer the value is to 1.0, the better, as this will indicate that the model can predict if a review is Favourable or Not Favourable with little bias and little variance. Though a value too close to 1.0 may indicate that there is variance in the training model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "roc_auc = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC (Area Under ROC): 0.9283\n"
     ]
    }
   ],
   "source": [
    "# Print the evaluation result\n",
    "print(f\"Test AUC (Area Under ROC): {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Baseline Model determined that the AUC was **0.9283**. This is indicative of a model with little variance and little bias. Making the Baseline Machine Learning model to perform well with its predictive power.\n",
    "\n",
    "The below `Code Block` shows a sample of the predictive power of the Machine Learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Predictions:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 304:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+-----------------------------------------+\n",
      "|text                |label|prediction|probability                              |\n",
      "+--------------------+-----+----------+-----------------------------------------+\n",
      "|Good luck trying to |0    |0.0       |[0.9802595063074832,0.019740493692516847]|\n",
      "|The filters don't ke|0    |1.0       |[0.2981005455029585,0.7018994544970415]  |\n",
      "|The Heavy duty filte|0    |0.0       |[0.9999920802142824,7.91978571756946E-6] |\n",
      "|Lasted maybe 2 weeks|0    |0.0       |[0.9999126699692661,8.733003073391199E-5]|\n",
      "|It's a piece of plas|0    |1.0       |[0.14236229117230803,0.857637708827692]  |\n",
      "|They don't work in t|0    |1.0       |[0.48171669748994517,0.5182833025100548] |\n",
      "|*** THIS ICE MACHINE|0    |0.0       |[0.999996564128657,3.4358713429938348E-6]|\n",
      "|[[VIDEOID:7101ea2ab5|0    |0.0       |[0.915184742549061,0.08481525745093899]  |\n",
      "|These shelves are ex|0    |0.0       |[0.5893658951191919,0.4106341048808081]  |\n",
      "|I just changed my fi|0    |0.0       |[0.6294695027946228,0.37053049720537723] |\n",
      "|Installed new valve |0    |0.0       |[0.9137288144959024,0.08627118550409762] |\n",
      "|I bought a brand new|0    |0.0       |[0.9999188138822847,8.118611771534834E-5]|\n",
      "|I do not normally ri|0    |0.0       |[0.9949617853088492,0.005038214691150844]|\n",
      "|Broke at the base ne|0    |0.0       |[0.9918631509235124,0.008136849076487596]|\n",
      "|It is smaller in dia|0    |0.0       |[0.8789509368325498,0.12104906316745023] |\n",
      "|We tried using the w|0    |0.0       |[0.9996409947630404,3.590052369596419E-4]|\n",
      "|Was not compatible w|0    |0.0       |[0.9427404471968828,0.05725955280311723] |\n",
      "|I don’t know what th|0    |0.0       |[0.9871188461653594,0.012881153834640613]|\n",
      "|The space on my coun|0    |0.0       |[0.8313418381890516,0.1686581618109484]  |\n",
      "|This is the second t|0    |0.0       |[0.9758694374855378,0.024130562514462217]|\n",
      "+--------------------+-----+----------+-----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Display some sample predictions\n",
    "print(\"Sample Predictions:\")\n",
    "df_predictions = predictions.withColumn(\"text\", substring(\"text\", 1, 20))\n",
    "\n",
    "df_predictions.select(\"text\", \"label\", \"prediction\", \"probability\").show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics\n",
    "\n",
    "Determining performance metrics of the Machine Learning model is important to determine whether it will be used to perform our Sentiment Analysis on the reviews or not. Below, the following metrics are calculated: Accuracy, Precision, Recall, and F1-Score. These metrics are analyzed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator_acc.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Precision\n",
    "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "precision = evaluator_precision.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Recall\n",
    "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "recall = evaluator_recall.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# F1-score\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluator_f1.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Metrics:\n",
      "Accuracy: 0.8969\n",
      "Precision: 0.8928\n",
      "Recall: 0.8969\n",
      "F1-score: 0.8914\n"
     ]
    }
   ],
   "source": [
    "# Print metrics\n",
    "print(f\"Model Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "Accuracy is the proportion of correctly classified reviews (Favourable or Not Favourable) out of all of the reviews. Our model has an accuracy of 0.8969, meaning that ~89.7% of all reviews were correctly classified as Favourable (Label = 1.0) or Not Favourable (Label = 0.0).\n",
    "\n",
    "#### Precision\n",
    "Precision measures how many of the predicted Favourable reviews were actually correct. Our model has a precision of 0.8928, meaning that ~89.3% of all predictions were correct when the model predicted a review as Favourable.\n",
    "\n",
    "#### Recall\n",
    "Recall measures how many of the actual Favourable reviews were correctly identified by the model. Our model has a recall of 0.8969, meaning that ~89.7% of all actual Favourable reviews were correctly predicted as Favourable.\n",
    "\n",
    "#### F1-Score\n",
    "The F1-Score is the harmonic mean of precision and recall, balancing both metrics. Our F1-Score of 0.8914 is reflective of a good balance between our precision and recall values, showing that the model effectively captures Favourable reviews, while minimizing False Positives and False Negatives.\n",
    "\n",
    "#### Overall\n",
    "These high values for our metrics suggest that the baseline Machine Learning model is performing well overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation and Hyperparameter Tuning\n",
    "\n",
    "We tune the Regularization parameter using Cross-Validation to determine if we can find an optimal setting for the Baseline Machine Learning Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.01, 0.1, 1.0]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(labelCol=\"label\"),\n",
    "                          numFolds=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1461:======================================================(12 + 0) / 12]\r"
     ]
    }
   ],
   "source": [
    "# Run cross-validation to choose the best model\n",
    "cv_model = crossval.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Test AUC (Cross-Validated): 0.9289\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model\n",
    "best_model = cv_model.bestModel\n",
    "cv_predictions = best_model.transform(test_data)\n",
    "cv_roc_auc = evaluator.evaluate(cv_predictions)\n",
    "\n",
    "print(f\"Best Model Test AUC (Cross-Validated): {cv_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Hyperparameter Tuning with Cross-Validation, the best model appears to have an AUC of 0.9289, only slightly higher than the baseline model. This is indicative of the predictive power of the model being slightly better after hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "#### Baseline\n",
    "\n",
    "The baseline machine learning model performed well using logistic regression on the following metrics:\n",
    "\n",
    "| **Metric**    | **Score**  | \n",
    "| ------------- | ---------- |\n",
    "| Accuracy      | 0.8969     |\n",
    "| Precision     | 0.8928     |\n",
    "| Recall        | 0.8969     |     \n",
    "| F1-Score      | 0.8914     |\n",
    "| AUC           | 0.9283     |\n",
    "\n",
    "#### Cross-Validated (After Hyperparameter Tuning)\n",
    "\n",
    "Best Model Test AUC: 0.9289\n",
    "\n",
    "Hyperparameter tuning appeared to slightly improved the model’s predictive power by increasing the AUC to 0.9289\n",
    "\n",
    "This demonstrates that tuning the regularization parameter (regParam) allowed the model to generalize better on unseen test data.\n",
    "\n",
    "#### Key Findings\n",
    "\n",
    "The Accuracy, Precision, Recall, and F1-Score metrics all indicated that the Machine Learning Model had high predictive power when it came to labelling a review as Favourable (Label = 1.0) or Not Favourable (Label = 0.0). \n",
    "\n",
    "The TF-IDF method seemed to work well and we were able to utilize it to create a valuable model with the predictive power we wanted. The dataset was large so we utilized Apache Spark to determine create our model with the TF-IDF method. We were required to lower our vocabulary due to system constraints (to a vocabulary of 5000), but this did not seem to interfere with the creation of our model.\n",
    "\n",
    "#### Future Work\n",
    "\n",
    "In the future, with greater computing resources, it would be ideal to create a model using Random Forests or deep learning models. It would also be ideal to perform more Hyperparameter tuning, though with such large datasets, it becomes cumbersome to test multiple hyperparameters on a grid, as the time it takes could take hours, or even days with large datasets and scarce computing resources.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The Machine Learning model created by our team appears to have been successful in determining whether a given review is Favourable or Not Favourable, with high metrics in Accuracy, Precision, Recall, and F1-Score. Also after tuning the Regularization Hyperparameter, the AUC score stayed relatively the same, indicating that there was little variance. If we had greater computing resources, we would certainly like to try various different classification models and tune different hyperparameters to fit the models needs, and see if we could achieve a higher AUC score with higher metrics also.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
