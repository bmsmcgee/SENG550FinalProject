{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENG 550 Final Project\n",
    "### Use the Amazon Appliances reviews dataset to develop a classifier or sentiment analyzer that can predict whether a given review is favorable or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "Our project uses the Amazon Appliances [reviews dataset](https://amazon-reviews-2023.github.io/) to develop a sentiment analyzer classification model. By combining star ratings and textual content, the model is trained to predict whether a review leans positively or negatively towards a product. This approach offers a way to quickly grasp the general sentiment of a product and assist shoppers in filtering through large volumes of product feedback more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "### Selected Problem\n",
    "\n",
    "The problem aims to distinguish between favourable and unfavourable appliance reviews based on their text and accompanying reviews.\n",
    "\n",
    "### Why is it Important?\n",
    "\n",
    "Spending time reading review after review on a product becomes a burden. It is easy to misinterpret the mood behind a set of comments online which can easily lead to poor purchase decisions. A quick, automated sentiment indicator can ease the burden and establish a neutral decision making process.\n",
    "\n",
    "### What have Others Done in this Space?\n",
    "\n",
    "Researchers have performed [sentiment analysis](https://medium.com/@nafisaidris413/a-beginners-guide-for-product-review-sentiment-analysis-0de1f451167d) using Machine Learning and Natural Language Processing to automatically classify reviews as positive, negative, or neutral. Not only has sentiment analysis been applied to product reviews, it has also been applied to [social media](https://buffer.com/social-media-terms/sentiment-analysis) to determine how people perceive and talk about products and brands. This proves that data-driven classifiers are able to provide sentiment analysis scores for assist people in their daily lives, whether its to determine how their personal brand is viewed or how a to make an informed purchase through product review.\n",
    "\n",
    "### Existing gaps?\n",
    "\n",
    "Current solutions rely on product ratings to provide consumers with a sense of trust and quality to help them make purchasing decisions. This can be seen simply by going to any Amazon product and checking the reviews. Some reviews are informative with many positives about the product, though the product receives less than a rating of 5-stars, or the review is not informative whatsoever with a rating of 5-stars. Other times the reviews are clearly biased or the customer who leaves the review is disgruntled, leading to a 1- or 2-star rating. Using a combination of product star rating and textual review content, we are attempting to reveal patterns in product reviews that a rating alone might miss.\n",
    "\n",
    "### Data Analysis Questions\n",
    "\n",
    "1. Does text-based features add value beyond just a numerical rating?\n",
    "2. Are there certain words which portray a stronger positve or negative sentiment?\n",
    "3. How will adding text preprocessing impact accuracy?\n",
    "4. Which models work best with this data?\n",
    "\n",
    "### What is Proposed\n",
    "\n",
    "We are proposing a text classification pipeline that merges a product's star rating and textual features.\n",
    "\n",
    "### What are your Main Findings?\n",
    "\n",
    "To determine customer opinion on various products within the Appliance category in Amazon's online store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "### Exploration of Data Features and Refinement of Feature Space\n",
    "\n",
    "In this section, we focused on understanding the raw data collected from the collected [datasets](https://amazon-reviews-2023.github.io/) and transform them into a format suitable for model training. We begin by loading the Amazon Appliance reviews dataset and its corresponding metadata. We will explore the structure of the data, examine the distribution of fields we are interested in (like ratings), and assess the overall quality of the text reviews associated with the products. After we gain a thorough understanding, we apply a series of preprocessing techniques to clean and refine the text data. The goal here is to ultimately develop a set of features that can be fed into a machine learning model for sentiment classification.\n",
    "\n",
    "#### Key Steps\n",
    "\n",
    "1. **Loading the Data:**\n",
    "We will loaf the `Appliances.jsonl` (reviews) and `meta_Appliances.jsonl` (metadata) using Apache Spark to avoid memory overload\n",
    "\n",
    "2. **Initial Inspection and Basic Statistics:**\n",
    "We will look at a few sample rows, check data types, count missing values, and examine distributions.\n",
    "\n",
    "3. **Textual Data Exploration:**\n",
    "We consider the nature of each review such as its length, the character composition, and common words. This should help guide our text cleaning decision.\n",
    "\n",
    "4. **Data Cleaning:**\n",
    "We clean the text by methods such as lowercasing the characters, removing punctuation, stripping leading and/or trailing whitespaces.\n",
    "\n",
    "5. **Feature Transformation:**\n",
    "We will use Spark Machine Learning's feature extraction tools to convert raw text into numeric features that are typically suitable for machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Data\n",
    "\n",
    "The datasets are provided in `*.jsonl` format, which means each line is a separate JSON object representing a single review or product's metadata. We will use `SparkSession` to read the files which will handle the data in a distributed manner, effectively avoiding a potential kernel crash. Spark's lazy evaluation, transformations, and actions will manage memory usage of the large `.jsonl` files.\n",
    "\n",
    "The two main data sources:\n",
    "1. **Review File (`Appliances.jsonl`):**\n",
    "Contains user-level reviews with fields such as `rating`, `title`, `text`, and `helpful_vote`.\n",
    "\n",
    "2. **Metada File (`meta_Appliaces.jsonl`):**\n",
    "Contains product-level information like `main_category`, `average_rating`, and `price`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.sql.functions import col, isnan, when, count, expr, sum, size, lower, regexp_replace, min, avg, max\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, BooleanType, IntegerType, ArrayType, MapType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a Spark Session\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .master(\"local\")\n",
    "        .appName(\"Amazon Review Analysis\") \n",
    "        .config(\"spark.ui.showConsoleProgress\", \"false\")\n",
    "        .config(\"spark.executor.memory\", \"4g\")\n",
    "        .config(\"spark.driver.memory\", \"4g\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "# Only using columns needed for analysis for Reviews\n",
    "reviews_schema = StructType([\n",
    "    StructField(\"rating\", FloatType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"text\", StringType(), True),\n",
    "    StructField(\"helpful_vote\", IntegerType() , True),\n",
    "    StructField(\"asin\", StringType(), True),\n",
    "    StructField(\"parent_asin\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Only using columns needed for analysis for Metadata\n",
    "meta_schema = StructType([\n",
    "    StructField(\"main_category\", StringType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"average_rating\", FloatType(), True),\n",
    "    StructField(\"rating_number\", IntegerType(), True),\n",
    "    StructField(\"price\", FloatType(), True),\n",
    "    StructField(\"categories\", ArrayType(StringType(), True), True),\n",
    "    StructField(\"parent_asin\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Point to the location where the .jsonl files are\n",
    "reviews_file = \"./datasets/Appliances.jsonl\"\n",
    "meta_file = \"./datasets/meta_Appliances.jsonl\"\n",
    "\n",
    "# Use the schema when reading the JSON file for Reviews\n",
    "df_reviews = spark.read.schema(reviews_schema).json(reviews_file)\n",
    "\n",
    "# Use the schema when reading the JSON file for Meta\n",
    "df_meta = spark.read.schema(meta_schema).json(meta_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Inspection & Basic Statistics\n",
    "\n",
    "First it is important to understand the size of the dataset we are dealing with and the distribution of ratings. Using Spark actions like `show()` and `count()` we determine some initial statistics about both datasets which will be helpful to visualize them. We also would like to know how many values in each column of the datasets are `null`, `None`, and `NaN`, in case we need to do some backfilling or should ignore those sets completely. We can also display a few rows of each dataset which makes sure that the datasets were loaded successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Structure Inspection\n",
    "\n",
    "For the structure of each dataset we will check the datasets dimensions, schema, and preview the data to understand each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appliance Reviews dataset dimensions: 2128605 rows, 6 columns\n",
      "Appliance Metadata dataset dimensions: 94327 rows, 7 columns\n"
     ]
    }
   ],
   "source": [
    "# Printing Dimensions\n",
    "print(f\"Appliance Reviews dataset dimensions: {df_reviews.count()} rows, {len(df_reviews.columns)} columns\")\n",
    "print(f\"Appliance Metadata dataset dimensions: {df_meta.count()} rows, {len(df_meta.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appliance Review Schema:\n",
      "root\n",
      " |-- rating: float (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- helpful_vote: integer (nullable = true)\n",
      " |-- asin: string (nullable = true)\n",
      " |-- parent_asin: string (nullable = true)\n",
      "\n",
      "\n",
      "Appliance Metadata Schema:\n",
      "root\n",
      " |-- main_category: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- average_rating: float (nullable = true)\n",
      " |-- rating_number: integer (nullable = true)\n",
      " |-- price: float (nullable = true)\n",
      " |-- categories: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- parent_asin: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing Schemas\n",
    "print(f\"Appliance Review Schema:\")\n",
    "df_reviews.printSchema()\n",
    "\n",
    "print(f\"\\nAppliance Metadata Schema:\")\n",
    "df_meta.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appliance Review dataset preview:\n",
      "+------+--------------------+--------------------+------------+----------+-----------+\n",
      "|rating|               title|                text|helpful_vote|      asin|parent_asin|\n",
      "+------+--------------------+--------------------+------------+----------+-----------+\n",
      "|   5.0|          Work great|work great. use a...|           0|B01N0TQ0OH| B01N0TQ0OH|\n",
      "|   5.0|   excellent product|Little on the thi...|           0|B07DD2DMXB| B07DD37QPZ|\n",
      "|   5.0|     Happy customer!|Quick delivery, f...|           0|B082W3Z9YK| B082W3Z9YK|\n",
      "|   5.0|       Amazing value|I wasn't sure whe...|           0|B078W2BJY8| B078W2BJY8|\n",
      "|   5.0|         Dryer parts|Easy to install g...|           0|B08C9LPCQV| B08C9LPCQV|\n",
      "|   5.0|DO NOT purchase t...|After buying this...|           0|B08D6RFV6D| B099ZKQJHK|\n",
      "|   2.0|They don't fit pr...|Not the best quality|           0|B001TH7GZA| B001TH7H0O|\n",
      "|   5.0|          Five Stars|Part came quickly...|           0|B00AF7WZTM| B00AF7WZTM|\n",
      "|   5.0|          Five Stars|Always arrive in ...|           0|B001H05AXY| B001H05AXY|\n",
      "|   2.0|Company is phenom...|The company respo...|           0|B085C6C7WH| B085C6C7WH|\n",
      "+------+--------------------+--------------------+------------+----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview the Data\n",
    "print(f\"Appliance Review dataset preview:\")\n",
    "df_reviews.show(10, truncate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appliance Metadata dataset preview:\n",
      "+--------------------+--------------------+--------------+-------------+-----+--------------------+-----------+\n",
      "|       main_category|               title|average_rating|rating_number|price|          categories|parent_asin|\n",
      "+--------------------+--------------------+--------------+-------------+-----+--------------------+-----------+\n",
      "|Industrial & Scie...|ROVSUN Ice Maker ...|           3.7|           61| NULL|[Appliances, Refr...| B08Z743RRD|\n",
      "|Tools & Home Impr...|HANSGO Egg Holder...|           4.2|           75| NULL|[Appliances, Part...| B097BQDGHJ|\n",
      "|Tools & Home Impr...|Clothes Dryer Dru...|           3.5|           18| NULL|[Appliances, Part...| B00IN9AGAE|\n",
      "|Tools & Home Impr...|154567702 Dishwas...|           4.5|           26| NULL|[Appliances, Part...| B0C7K98JZS|\n",
      "|Tools & Home Impr...|Whirlpool W109185...|           3.8|           12|25.07|[Appliances, Part...| B07QZHQTVJ|\n",
      "|Tools & Home Impr...|1841N030 - Brown ...|           4.5|            7| NULL|[Appliances, Part...| B00GS4892I|\n",
      "|          Appliances|WD12X10327 Rack R...|           4.6|          323| 8.99|[Appliances, Part...| B07W42P978|\n",
      "|Tools & Home Impr...|SAMSUNG Cap-Handl...|           4.0|           12|53.68|[Appliances, Part...| B078ZF9JS1|\n",
      "|         Amazon Home|G.a HOMEFAVOR Col...|           4.5|          326| NULL|[Small Appliance ...| B083Q6Y54F|\n",
      "|Tools & Home Impr...|3-pack OnePurify ...|           4.3|          236| NULL|[Appliances, Part...| B00KAS9ZMG|\n",
      "+--------------------+--------------------+--------------+-------------+-----+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Appliance Metadata dataset preview:\")\n",
    "df_meta.show(10, truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values Inspection\n",
    "\n",
    "Missing values is one of the most common headaches in datasets. We need to check for them in both datasets to ensure that we can confidently use the data, else we have to consider backfilling the missing data or not using it at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appliance Reviews Counted Missing Values per Column\n",
      "+------+-----+----+----+-----------+------------+\n",
      "|rating|title|text|asin|parent_asin|helpful_vote|\n",
      "+------+-----+----+----+-----------+------------+\n",
      "|     0|    0|  95|   0|          0|           0|\n",
      "+------+-----+----+----+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews_float_columns = [c for c in df_reviews.columns if df_reviews.schema[c].dataType.simpleString() == \"float\"]\n",
    "reviews_string_columns = [c for c in df_reviews.columns if df_reviews.schema[c].dataType.simpleString() == \"string\"]\n",
    "reviews_integer_columns = [c for c in df_reviews.columns if df_reviews.schema[c].dataType.simpleString() == \"int\"]\n",
    "\n",
    "reviews_float_null = df_reviews.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in reviews_float_columns])\n",
    "reviews_string_null = df_reviews.select([sum((col(c).isNull() | (col(c) == \"\")).cast(\"int\")).alias(c) for c in reviews_string_columns])\n",
    "reviews_integer_null = df_reviews.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in reviews_integer_columns])\n",
    "\n",
    "df_reviews_null = (\n",
    "    reviews_float_null.select(*(col(c).alias(f\"{c}\") for c in reviews_float_null.columns))\n",
    "    .crossJoin(reviews_string_null.select(*(col(c).alias(f\"{c}\") for c in reviews_string_null.columns)))\n",
    "    .crossJoin(reviews_integer_null.select(*(col(c).alias(f\"{c}\") for c in reviews_integer_null.columns)))\n",
    ")\n",
    "\n",
    "print(f\"Appliance Reviews Counted Missing Values per Column\")\n",
    "df_reviews_null.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appliance Metadata Counted Missing Values per Column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+-------------+-----+-----------+-------------+----------+\n",
      "|average_rating|price|main_category|title|parent_asin|rating_number|categories|\n",
      "+--------------+-----+-------------+-----+-----------+-------------+----------+\n",
      "|             0|47601|         4676|    9|          0|            0|         0|\n",
      "+--------------+-----+-------------+-----+-----------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define lists of column names for each type\n",
    "meta_float_columns = [c for c in df_meta.columns if df_meta.schema[c].dataType.simpleString() == \"float\"]\n",
    "meta_string_columns = [c for c in df_meta.columns if df_meta.schema[c].dataType.simpleString() == \"string\"]\n",
    "meta_integer_columns = [c for c in df_meta.columns if df_meta.schema[c].dataType.simpleString() == \"int\"]\n",
    "meta_array_columns = [c for c in df_meta.columns if df_meta.schema[c].dataType.simpleString().startswith(\"array\")]\n",
    "\n",
    "# Compute NULL counts for float columns\n",
    "meta_float_null = df_meta.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in meta_float_columns])\n",
    "\n",
    "# Compute NULL or empty counts for string columns\n",
    "meta_string_null = df_meta.select([sum((col(c).isNull() | (col(c) == \"\")).cast(\"int\")).alias(c) for c in meta_string_columns])\n",
    "\n",
    "# Compute NULL counts for integer columns\n",
    "meta_integer_null = df_meta.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in meta_integer_columns])\n",
    "\n",
    "# Compute NULL or empty counts for array columns\n",
    "meta_array_null = df_meta.select([sum((col(c).isNull() | expr(f\"exists({c}, x -> x == '')\")).cast(\"int\")).alias(c)for c in meta_array_columns])\n",
    "\n",
    "# Combine all the results into one DataFrame\n",
    "df_meta_null = (\n",
    "    meta_float_null.select(*(col(c).alias(f\"{c}\") for c in meta_float_null.columns))\n",
    "    .crossJoin(meta_string_null.select(*(col(c).alias(f\"{c}\") for c in meta_string_null.columns)))\n",
    "    .crossJoin(meta_integer_null.select(*(col(c).alias(f\"{c}\") for c in meta_integer_null.columns)))\n",
    "    .crossJoin(meta_array_null.select(*(col(c).alias(f\"{c}\") for c in meta_array_null.columns)))\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(f\"Appliance Metadata Counted Missing Values per Column\")\n",
    "df_meta_null.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicates\n",
    "\n",
    "Catching if there is duplicate data is important so that we do not have skewed data. All the data should be unique. Duplicate data will be handled during data cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appliance Reviews Duplicate Data: 29492\n",
      "Appliance Metadate Duplicate Data: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Appliance Reviews Duplicate Data: {df_reviews.count() - df_reviews.distinct().count()}\")\n",
    "print(f\"Appliance Metadate Duplicate Data: {df_meta.count() - df_meta.distinct().count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Data\n",
    "\n",
    "We examine the statistical summaries for both the Reviews and Metadata. This helps us spot outliers and check if there are unexpected ranges that we have to look out for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appliance Reviews Statistical Summary\n",
      "+-------+------------------+--------------------+--------------------+------------------+--------------------+--------------------+\n",
      "|summary|            rating|               title|                text|      helpful_vote|                asin|         parent_asin|\n",
      "+-------+------------------+--------------------+--------------------+------------------+--------------------+--------------------+\n",
      "|  count|           2128605|             2128605|             2128605|           2128605|             2128605|             2128605|\n",
      "|   mean| 4.221502345432807|                 NaN|1.0294495574587156E9|0.9288867591685634|1.5550635848728814E9|1.5550635848728814E9|\n",
      "| stddev|1.3808261737697332|                 NaN|1.064196457532015...|12.526794316769578|1.4548141211071746E9|1.4548141211071746E9|\n",
      "|    min|               1.0|                   !|                    |                 0|          0967805929|          0967805929|\n",
      "|    max|               5.0|üßäü•∂ AMAZING ü§©  ...|üßêdoesn‚Äôt filter ...|              5704|          B0CFQVYFWC|          B0CKR66M1V|\n",
      "+-------+------------------+--------------------+--------------------+------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Appliance Reviews Statistical Summary\")\n",
    "df_reviews.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appliance Metadata Statistical Summary\n",
      "+-------+--------------+--------------------+------------------+------------------+------------------+--------------------+\n",
      "|summary| main_category|               title|    average_rating|     rating_number|             price|         parent_asin|\n",
      "+-------+--------------+--------------------+------------------+------------------+------------------+--------------------+\n",
      "|  count|         89651|               94327|             94327|             94327|             46726|               94327|\n",
      "|   mean|          NULL|  1.1113368793875E10| 4.118858857941276|136.36790102515715|  86.4799539034291|4.0776468745555553E9|\n",
      "| stddev|          NULL|3.142601103602334...|0.8640397544170944| 977.5160999553561|325.31839674168526| 3.745278366512328E9|\n",
      "|    min|AMAZON FASHION|                    |               1.0|                 1|              0.01|          0967805929|\n",
      "|    max|   Video Games|ùüÆùü¨ùüÆùüØùô™ùô•ùôúùôß?...|               5.0|             90203|          21095.62|          B0CKR66M1V|\n",
      "+-------+--------------+--------------------+------------------+------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Appliance Metadata Statistical Summary\")\n",
    "df_meta.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textual Data Exploration\n",
    "\n",
    "The main predictive feature of the model will likely be the `text` column in the Appliance Review dataset. It is important that we are able to understand its quality. We find answers to questions such as are the reviews too short or lone? Do they contain descriptive terms or just a few words? We also need to consider if there is text in different languages other than english.\n",
    "\n",
    "What we will do is start by analyzing the length of the reviews in terms of word count. This will help guide us in the direction we want. If the text is too short, maybe we need to rely more on ratings or metadata. If text is rich, a text-based sentiment analysis may just work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appliance Reviews with Raw Words and Character Length included\n",
      "+------+--------------------+--------------------+------------+----------+-----------+--------------------+----------------+\n",
      "|rating|               title|                text|helpful_vote|      asin|parent_asin|           words_raw|character_length|\n",
      "+------+--------------------+--------------------+------------+----------+-----------+--------------------+----------------+\n",
      "|   5.0|          Work great|work great. use a...|           0|B01N0TQ0OH| B01N0TQ0OH|[work, great., us...|               8|\n",
      "|   5.0|   excellent product|Little on the thi...|           0|B07DD2DMXB| B07DD37QPZ|[little, on, the,...|               5|\n",
      "|   5.0|     Happy customer!|Quick delivery, f...|           0|B082W3Z9YK| B082W3Z9YK|[quick, delivery,...|               5|\n",
      "|   5.0|       Amazing value|I wasn't sure whe...|           0|B078W2BJY8| B078W2BJY8|[i, wasn't, sure,...|              57|\n",
      "|   5.0|         Dryer parts|Easy to install g...|           0|B08C9LPCQV| B08C9LPCQV|[easy, to, instal...|               9|\n",
      "|   5.0|DO NOT purchase t...|After buying this...|           0|B08D6RFV6D| B099ZKQJHK|[after, buying, t...|              33|\n",
      "|   2.0|They don't fit pr...|Not the best quality|           0|B001TH7GZA| B001TH7H0O|[not, the, best, ...|               4|\n",
      "|   5.0|          Five Stars|Part came quickly...|           0|B00AF7WZTM| B00AF7WZTM|[part, came, quic...|              10|\n",
      "|   5.0|          Five Stars|Always arrive in ...|           0|B001H05AXY| B001H05AXY|[always, arrive, ...|              14|\n",
      "|   2.0|Company is phenom...|The company respo...|           0|B085C6C7WH| B085C6C7WH|[the, company, re...|              22|\n",
      "+------+--------------------+--------------------+------------+----------+-----------+--------------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "Minimum, Average, and Maximum character length of the Appliance Reviews\n",
      "+---------------------+---------------------+---------------------+\n",
      "|min(character_length)|avg(character_length)|max(character_length)|\n",
      "+---------------------+---------------------+---------------------+\n",
      "|                    0|   32.026548373230355|                 3740|\n",
      "+---------------------+---------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_reviews = df_reviews.fillna({\"text\": \"\"})\n",
    "df_reviews = df_reviews.withColumn(\"text\", col(\"text\").cast(StringType()))\n",
    "\n",
    "tokenizer_reviews = Tokenizer(inputCol=\"text\", outputCol=\"words_raw\")\n",
    "df_tokenizer_reviews = tokenizer_reviews.transform(df_reviews)\n",
    "\n",
    "df_tokenizer_reviews = df_tokenizer_reviews.withColumn(\"character_length\", size(col(\"words_raw\")))\n",
    "\n",
    "print(f\"Appliance Reviews with Raw Words and Character Length included\")\n",
    "df_tokenizer_reviews.show(10, truncate=True)\n",
    "\n",
    "print(f\"\\nMinimum, Average, and Maximum character length of the Appliance Reviews\")\n",
    "df_tokenizer_reviews.select(min(\"character_length\"), avg(\"character_length\"), max(\"character_length\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
